{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mmh3\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import chisquare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chisquare_test(sample, power=1.16, alpha=1, skip=50):\n",
    "    unique, counts = np.unique(sample, return_counts=True)\n",
    "    counts[::-1].sort()\n",
    "\n",
    "    frequencies = np.array([alpha / np.power(i, power) for i in range(1, len(counts) + 1)])\n",
    "    zipf_counts = np.ceil(frequencies)\n",
    "\n",
    "    chi = chisquare(counts[skip:], zipf_counts[skip:])\n",
    "    return chi[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_distributed_test(test, sample, paral_size=10):\n",
    "    distributed_sample = defaultdict(list)\n",
    "    for el in sample:\n",
    "        distributed_sample[mmh3.hash(str('qwerty' + el)) % paral_size].append(el)\n",
    "\n",
    "    print('############################')\n",
    "    print('PARTITIONING ', paral_size)\n",
    "    for ds in distributed_sample:\n",
    "        print('PARTITION ', ds)\n",
    "        data = distributed_sample[ds]\n",
    "\n",
    "        power, alpha = parameter_estimation(data)\n",
    "        print(power, alpha)\n",
    "        p_value = test(data, power, alpha)\n",
    "\n",
    "        print('P VALUE', p_value)\n",
    "        print('#######')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameter_estimation(sample):\n",
    "    unique, counts = np.unique(sample, return_counts=True)\n",
    "    counts = -np.sort(-counts)\n",
    "    start = 10\n",
    "    counts = counts[np.where(counts >= 5)]\n",
    "    counts = counts[start:]\n",
    "    m = len(counts)\n",
    "    logf = np.log(counts)\n",
    "    logn = np.log(np.arange(start=1, stop=m + 1, step=1) + start)\n",
    "    s = (m * np.dot(logf, logn) / np.sum(logn) - np.sum(logf)) / (np.sum(logn) - m * np.dot(logn, logn) / np.sum(logn))\n",
    "    alpha = np.exp((s * np.dot(logn, logn) + np.dot(logn, logf)) / np.sum(logn))\n",
    "    return (s, alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test war and peace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################\n",
      "PARTITIONING  1\n",
      "PARTITION  0\n",
      "1.2227028082024947 222358.59781881908\n",
      "P VALUE 1.0\n",
      "#######\n",
      "############################\n",
      "PARTITIONING  2\n",
      "PARTITION  0\n",
      "1.2077008964973277 83434.67620023729\n",
      "P VALUE 1.0\n",
      "#######\n",
      "PARTITION  1\n",
      "1.2505044772585165 119453.87371271935\n",
      "P VALUE 1.0\n",
      "#######\n",
      "############################\n",
      "PARTITIONING  3\n",
      "PARTITION  1\n",
      "1.2354748609715989 67851.730673141\n",
      "P VALUE 1.0\n",
      "#######\n",
      "PARTITION  0\n",
      "1.197603246287541 46202.83444819046\n",
      "P VALUE 1.0\n",
      "#######\n",
      "PARTITION  2\n",
      "1.2701013591275672 79214.29765518052\n",
      "P VALUE 1.0\n",
      "#######\n",
      "############################\n",
      "PARTITIONING  4\n",
      "PARTITION  2\n",
      "1.2067635690946057 36416.36998633147\n",
      "P VALUE 1.0\n",
      "#######\n",
      "PARTITION  1\n",
      "1.2428042282523715 48128.99709212303\n",
      "P VALUE 1.0\n",
      "#######\n",
      "PARTITION  0\n",
      "1.2259311576547987 40191.783390759614\n",
      "P VALUE 1.0\n",
      "#######\n",
      "PARTITION  3\n",
      "1.2774181699879095 59525.340219050195\n",
      "P VALUE 1.0\n",
      "#######\n"
     ]
    }
   ],
   "source": [
    "file = open('war_and_peace.txt', 'r')\n",
    "text = file.read().lower()\n",
    "words = re.sub('\\W', ' ', text).split()[:500000]\n",
    "\n",
    "tests = {'chi': chisquare_test}\n",
    "paral_sizes = range(1, 5)\n",
    "for name in tests:\n",
    "    for ps in paral_sizes:\n",
    "        hash_distributed_test(tests[name], words, paral_size=ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test lognormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9278371106435572 142204.5470359915\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "sample = np.random.lognormal(mean=0.3, sigma=2, size=100000)\n",
    "sample = np.array(sample, dtype=np.int)\n",
    "s, alpha = parameter_estimation(sample)\n",
    "print(s, alpha)\n",
    "print(chisquare_test(sample, s, alpha))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test exponential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.895775352728193 110649152.47327146\n",
      "6.057928228323907e-09\n"
     ]
    }
   ],
   "source": [
    "sample = np.random.exponential(scale=1.0 / 0.125, size=100000)\n",
    "sample = np.array(sample, dtype=np.int)\n",
    "s, alpha = parameter_estimation(sample)\n",
    "print(s, alpha)\n",
    "print(chisquare_test(sample, s, alpha))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
